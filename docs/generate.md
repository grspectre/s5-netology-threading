Ниже — реалистичный 7‑дневный план «под ключ» под критерии с картинки и шаги ДЗ. Он построен так, чтобы ты мог приносить мне **конкретные куски исходников/конфиги** по каждому пункту, и я помогал довести до готового решения (код + метрики + скриншоты + выводы + текст в презентацию).

## Что нужно подготовить (в первый час)
1) Репозиторий на GitHub (ветка `perf-assignment`).
2) Зафиксировать окружение:
- Java / Spring Boot версии
- БД (PostgreSQL/MySQL/H2), способ запуска (Docker/локально)
- Как запускается парсинг: HTTP endpoint? CLI? scheduled job? очередь?

3) Сразу завести папку в репозитории:
- `docs/` — туда потом скриншоты Grafana/Jaeger, выводы, настройки JVM
- `load-tests/` — сценарии нагрузки (любым способом)

---

## День 1 — “База”: Actuator + Prometheus + Grafana (чтобы уже были баллы)
**Цель:** получить `/actuator/health`, `/actuator/metrics`, `/actuator/prometheus` и первый дашборд.

**Делаем:**
1) Подключаем зависимости:
- `spring-boot-starter-actuator`
- `micrometer-registry-prometheus`

2) Включаем эндпоинты Actuator, especially:
- `health`, `info`, `metrics`, `prometheus`, `threaddump`
- (очень важно по критериям) метрика `http.server.requests`

3) Поднимаем Prometheus + Grafana (обычно через docker-compose), подключаем datasource, импортируем любой базовый Spring Boot dashboard или делаем минимальный.

**Артефакты для сдачи:**
- Скрин `/actuator/metrics` и `/actuator/prometheus`
- Скрин Grafana: RPS/latency, CPU, memory, GC (что получится из дефолта)
- Короткое описание в `docs/day1.md`: что подключено и как запускать

**Что ты даёшь мне, чтобы я сделал точные правки:**
- `build.gradle`/`pom.xml`
- `application.yml`/`application.properties`
- как называется главный модуль/пакет
- как происходит парсинг (класс/метод/endpoint)

---

## День 2 — Кастомные метрики парсинга (Micrometer): время, успех/ошибка, записи в БД
**Цель:** закрыть Шаг 1 и часть критериев “кастомные метрики”.

**Делаем метрики:**
1) `Timer` — время выполнения парсинга (лучше `Timer.Sample` → `sample.stop(timer)`).
2) `Counter` — успешные парсинги.
3) `Counter` — ошибочные парсинги (с тегом типа ошибки/исключения по необходимости).
4) `Counter` или `DistributionSummary` — количество записей, реально записанных в БД.
5) (опционально, но полезно) `Gauge` — размер очереди/число активных потоков, если есть пул.

Важно: метрики должны быть **в нужном месте** — вокруг «бизнес-операции парсинга», а не вокруг контроллера.

**Параллельно:** в Grafana добавляем панели под эти метрики:
- `rate(parser_success_total[1m])`
- p50/p95/p99 по Timer
- количество вставленных записей

**Артефакты:**
- commit с метриками
- скрины графиков, где видно рост счетчиков и распределение времени

**Что ты даёшь мне:**
- сервис/класс, где выполняется парсинг
- где происходит сохранение в БД (Repository/DAO), batch insert или по одной записи
- пример формата входных данных (файл/строка)

---

## День 3 — Нагрузочный прогон + throughput/latency + thread dump из Actuator
**Цель:** показать “реальный тест” и уметь интерпретировать базовые метрики + thread dump.

**Делаем:**
1) Выбираем способ нагрузки:
- простой: много запросов на endpoint парсинга (если есть HTTP)
- если парсинг по файлу: отдельный endpoint “запустить парсинг N раз” или локальный runner

2) Снимаем:
- throughput (RPS/операций в секунду)
- latency (p95/p99 из Timer’а и/или `http.server.requests`)
- ошибки

3) Thread dump:
- снимаем `/actuator/threaddump` во время нагрузки
- ищем блокировки, `WAITING`, `BLOCKED`, contention на synchronized/locks, проблемы пула

**Артефакты:**
- скриншоты Grafana под нагрузкой
- пример thread dump + краткая интерпретация (2–5 тезисов)

**Что ты даёшь мне:**
- точный endpoint/способ запуска парсинга
- текущие настройки пула потоков (если есть)
- лог/вывод работы приложения во время нагрузки (по желанию)

---

## День 4 — Профилирование (VisualVM или JFR): CPU, hot methods, GC, heap dump
**Цель:** закрыть Шаг 2–3 по диагностике и показать “как работал”.

**Делаем:**
1) Включаем JFR (или VisualVM) и запускаем с нагрузкой.
2) Снимаем:
- CPU Hot Methods (самые дорогие методы)
- Allocation / Object allocation (что больше всего аллоцирует)
- GC pauses / frequency
3) Делаем heap dump (для VisualVM) или Memory view (для JFR) и фиксируем top потребителей.

**Артефакты:**
- 3–6 скриншотов: CPU, allocations, GC, heap dominators/крупные объекты
- `docs/day4.md`: выводы “что узкое место и почему”

**Что ты даёшь мне:**
- команду запуска приложения (или `Dockerfile`)
- версию JVM
- если есть логи GC — тоже полезно

---

## День 5 — JMH: сравнение реализаций парсинга (for vs stream vs parallelStream и т.п.)
**Цель:** закрыть пункт JMH + подкрепить оптимизацию цифрами.

**Делаем:**
1) Выделяем чистую функцию(и) парсинга, которую можно бенчмаркать без IO/БД:
- “вход: строка/массив строк → выход: список DTO”
2) Добавляем JMH модуль (лучше отдельный `jmh` sourceSet/модуль).
3) Пишем 2–4 бенчмарка:
- baseline (текущая реализация)
- альтернатива (for)
- stream/parallelStream (если уместно)
- (опционально) pre-sized коллекции, StringBuilder, reuse объектов и т.д.
4) Запускаем, фиксируем результаты.

**Артефакты:**
- результаты JMH в `docs/jmh-results.txt`
- 1–2 слайда в презентацию: таблица “вариант → ops/s → allocation rate”

**Что ты даёшь мне:**
- ключевой метод парсинга (код)
- типичный входной пример (несколько строк/файл)
- какие форматы/правила парсинга (CSV/JSON/HTML и т.п.)

---

## День 6 — Исправление деградации: N+1, индексы, аллокации, синхронизация
**Цель:** закрыть Шаг 4 и сделать заметные улучшения “до/после”.

**Варианты проблем и как доказать:**
1) **N+1 к БД**:
- увидеть по логам SQL/трейсам/метрикам и по росту времени
- исправить через batch insert, join fetch, in‑query, кеширование справочников, подготовку данных заранее

2) **Индексы**:
- выбрать 1–2 самые частые/тяжелые запросы
- показать `EXPLAIN` до/после
- добавить индекс(ы)

3) **Частые аллокации**:
- уменьшить создание временных объектов: pre-size коллекций, избегать лишних `substring`, regex, boxing
- доказать через JFR allocations / GC pressure

4) **Синхронизация/контеншн**:
- заменить `synchronized` map/list на `ConcurrentHashMap` / lock-free подход
- убрать глобальные locks
- ограничить критические секции
- доказать через thread dump / JFR “Locks”

**Артефакты:**
- “до/после” графики latency и throughput
- список изменений + почему это ускорило

**Что ты даёшь мне:**
- Repository/DAO слой и самые частые запросы
- сущности JPA/Hibernate (если есть)
- схему таблиц или миграции (Flyway/Liquibase)
- участок кода с синхронизацией/очередями/пулами

---

## День 7 — OpenTelemetry + Jaeger: трейсинг этапов парсинга и диаграммы
**Цель:** закрыть Шаг 5 и самый “дорогой” критерий: трейсинг + логирование времени этапов.

**Делаем:**
1) Подключаем OpenTelemetry (обычно через Java agent проще всего).
2) Поднимаем Jaeger (docker-compose).
3) Размечаем этапы парсинга спанами:
- чтение входа
- разбор/маппинг
- валидация
- сохранение в БД
- постобработка
4) В Jaeger показываем:
- trace
- waterfall/timeline
- где самая большая длительность

**Артефакты:**
- скрин Jaeger с трейсом одного запроса/запуска
- краткое описание как запустить: переменные окружения/параметры JVM

**Важно:** если захочешь, чтобы я помог “найти в интернете” точные зависимости/конфиги под твою версию Spring/Java, тебе нужно написать фразу **«Найди в интернете …»** или нажать **кнопку «Веб-поиск»** в интерфейсе — тогда я смогу опираться на актуальные инструкции/версии.

---

## Как мы будем работать “по пунктам” (шаблон твоих сообщений)
Чтобы я быстро давал готовые патчи/конфиги и текст для отчёта, присылай так:

1) **Контекст проекта** (один раз):
- Java, Spring Boot, БД, как запускать
- ссылка на репо или вставкой ключевые файлы
- где живёт парсинг: классы/методы

2) Для каждого шага — **минимальный набор файлов**:
- `pom.xml`/`build.gradle`
- `application.yml`
- класс парсера + сервис + сохранение в БД
- docker-compose (если есть)

И вопрос: “Сделай шаг N: …, дай код/конфиги и что заскриншотить”.

---

## С чего начать прямо сейчас (самое полезное)
Пришли:
1) `pom.xml` или `build.gradle`
2) `application.yml/properties`
3) код места, где запускается парсинг (endpoint/service/scheduler)
4) код места, где пишешь в БД (repository/service)

Я в ответ дам точный план правок “под твой проект”: какие зависимости добавить, какие beans/метрики завести, какие эндпоинты включить, и что именно проверять в Grafana/Actuator на твоих метриках.